<!doctype html> <html lang=en > <meta charset=UTF-8 > <meta name=viewport  content="width=device-width, initial-scale=1"> <link rel=stylesheet  href="/Jaynes.jl/libs/katex/katex.min.css"> <link rel=stylesheet  href="/Jaynes.jl/css/franklin.css"> <link rel=stylesheet  href="/Jaynes.jl/css/basic.css"> <link rel=icon  href="/Jaynes.jl/assets/favicon-32x32.png"> <title>Compilation</title> <header> <div class=blog-name > <img src="/Jaynes.jl/assets/jaynes.png" style="width: 63%"></div> <nav> <ol> <li><a href="/Jaynes.jl/">About</a> <br> <li><a href="/Jaynes.jl/architecture">Architecture</a> <br> <li><a href="/Jaynes.jl/compilation">Compilation</a> <br> <li><a href="/Jaynes.jl/related_work">Related work</a> </ol> <img src="/Jaynes.jl/assets/hamburger.svg" id=menu-icon > </nav> </header> <div class=franklin-content ><blockquote> <p>This is preliminary work&#33; This system is designed to be exploratory in the direction of compiling and optimizing probabilistic programs &#40;especially universal ones&#41;. Thus, this page will likely evolve over time.</p> </blockquote> <p>As a research system, the goal of Jaynes is to facilitate the exploration of compilation techniques for probabilistic programs. This includes static techniques &#40;facilitated by dataflow analysis and abstract interpretation&#41; and partial evaluation/specialization for inference ops. To approach these goals, Jaynes implements the generative function interface - but it does so by implementing each interface as staged programming pipeline. For interface methods which operate as lightweight tracing on top of normal program execution &#40;e.g. <code>simulate</code>, <code>generate</code>, <code>assess</code>, and <code>propose</code>&#41; - this staging is not yet utilized &#40;although it&#39;s certainly possible there are useful optimization for these methods&#41;.</p> <p>The methods <code>regenerate</code> and <code>update</code> are used for iterative inference algorithms like Metropolis-Hastings and sequential Monte Carlo. It is highly important that these interface methods are efficient - because the user is likely to call them many times during the deployment of iterative inference algorithms. <a href="https://femtomc.github.io/mrb_dynamic_specialization.pdf">To specialize these operations, Jaynes uses a combination of static analysis techniques.</a> <a href="https://femtomc.github.io/mrb_dynamic_specialization_prez.pdf">A simple &quot;flow chart&quot; style version is also available here.</a></p> <p>Leaving a discussion of these techniques to the links above, here&#39;s a speculative list of other interesting &quot;static analysis&quot; questions which might be interesting to explore:</p> <ol> <li><p>Representation transformations - this is the category of optimizations which alter the representation of the model program <span class=katex ><span class=katex-mathml ><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>P</mi></mrow><annotation encoding="application/x-tex">P</annotation></semantics></math></span><span class=katex-html  aria-hidden=true ><span class=base ><span class=strut  style="height:0.68333em;vertical-align:0em;"></span><span class="mord mathdefault" style="margin-right:0.13889em;">P</span></span></span></span> irrespective of inference operation or observations.</p> <li><p>Specialization transformations - this is the category of the optimizations discussed above. Roughly, this category likely looks like the following: given a tuple <span class=katex ><span class=katex-mathml ><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo stretchy=false >(</mo><mi>P</mi><mo separator=true >,</mo><mi>o</mi><mi>p</mi><mo separator=true >,</mo><mi>o</mi><mi>b</mi><mi>s</mi><mo stretchy=false >)</mo></mrow><annotation encoding="application/x-tex">(P, op, obs)</annotation></semantics></math></span><span class=katex-html  aria-hidden=true ><span class=base ><span class=strut  style="height:1em;vertical-align:-0.25em;"></span><span class=mopen >(</span><span class="mord mathdefault" style="margin-right:0.13889em;">P</span><span class=mpunct >,</span><span class=mspace  style="margin-right:0.16666666666666666em;"></span><span class="mord mathdefault">o</span><span class="mord mathdefault">p</span><span class=mpunct >,</span><span class=mspace  style="margin-right:0.16666666666666666em;"></span><span class="mord mathdefault">o</span><span class="mord mathdefault">b</span><span class="mord mathdefault">s</span><span class=mclose >)</span></span></span></span> - where <span class=katex ><span class=katex-mathml ><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>P</mi></mrow><annotation encoding="application/x-tex">P</annotation></semantics></math></span><span class=katex-html  aria-hidden=true ><span class=base ><span class=strut  style="height:0.68333em;vertical-align:0em;"></span><span class="mord mathdefault" style="margin-right:0.13889em;">P</span></span></span></span> is a model, <span class=katex ><span class=katex-mathml ><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>o</mi><mi>p</mi></mrow><annotation encoding="application/x-tex">op</annotation></semantics></math></span><span class=katex-html  aria-hidden=true ><span class=base ><span class=strut  style="height:0.625em;vertical-align:-0.19444em;"></span><span class="mord mathdefault">o</span><span class="mord mathdefault">p</span></span></span></span> is an inference operation, and <span class=katex ><span class=katex-mathml ><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>o</mi><mi>b</mi><mi>s</mi></mrow><annotation encoding="application/x-tex">obs</annotation></semantics></math></span><span class=katex-html  aria-hidden=true ><span class=base ><span class=strut  style="height:0.69444em;vertical-align:0em;"></span><span class="mord mathdefault">o</span><span class="mord mathdefault">b</span><span class="mord mathdefault">s</span></span></span></span> is a set of observations, specialize <span class=katex ><span class=katex-mathml ><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>o</mi><mi>p</mi></mrow><annotation encoding="application/x-tex">op</annotation></semantics></math></span><span class=katex-html  aria-hidden=true ><span class=base ><span class=strut  style="height:0.625em;vertical-align:-0.19444em;"></span><span class="mord mathdefault">o</span><span class="mord mathdefault">p</span></span></span></span>.</p> <li><p>Intermediate representations - currently, Jaynes operates using an SSA form IR representation provided by <a href="https://github.com/FluxML/IRTools.jl">IRTools.jl</a>. Is this the most convenient representation for the above transformations?</p> <li><p>Compiler hints and errors - given access to the IR for a model, we might provide analysis-driven hints to the user which helps them author models which are easier to optimize. Additionally, one could imagine more complicated analysis tools - <a href="https://dl.acm.org/doi/10.1145/3371087">like type inference based upon trace types</a> which operate during model staging and become associated with the model for use in inference.</p> </ol> <div class=page-foot > <div class=copyright > &copy; McCoy R. Becker. Last modified: November 26, 2020. Website built with <a href="https://github.com/tlienart/Franklin.jl">Franklin.jl</a>. </div> </div> </div>